{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from drsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Recurrent Survival Analysis in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Documentation](https://collinprather.github.io/drsa/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This project features a PyTorch implementation of the [Deep Recurrent Survival Analysis](https://arxiv.org/pdf/1809.02403.pdf) model that is intended for use on uncensored sequential data in which the event is known to occur at the last time step for each observation\n",
    "\n",
    "More specifically, this library is made up of two small modules.\n",
    "\n",
    "1. [`functions.py`](https://collinprather.github.io/drsa/functions/), which contains utilities for computing conventional survival analysis quantities, given a [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) of predicted conditional hazard rates.\n",
    "\n",
    "2. [`model.py`](https://collinprather.github.io/drsa/model/), which contains the `DRSA` class (a subclass of [`torch.nn.Module`](https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html)), and is easily extended to handle categorical embeddings, additional layers, or any other arbitrary PyTorch operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```\n",
    "$ pip install drsa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drsa.functions import event_time_loss, event_rate_loss\n",
    "from drsa.model import DRSA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random data\n",
    "batch_size, seq_len, n_features = (64, 25, 10)\n",
    "def data_gen(batch_size, seq_len, n_features):\n",
    "    samples = []\n",
    "    for _ in range(batch_size):\n",
    "        sample = torch.cat([torch.normal(mean=torch.arange(1., float(seq_len)+1)).unsqueeze(-1) for _ in range(n_features)], dim=-1)\n",
    "        samples.append(sample.unsqueeze(0))\n",
    "    return torch.cat(samples, dim=0)\n",
    "data = data_gen(batch_size, seq_len, n_features)\n",
    "\n",
    "# generating random embedding for each sequence\n",
    "n_embeddings = 10\n",
    "embedding_idx = torch.mul(\n",
    "    torch.ones(batch_size, seq_len, 1),\n",
    "    torch.randint(low=0, high=n_embeddings, size=(batch_size, 1, 1)),\n",
    ")\n",
    "\n",
    "# concatenating embeddings and features\n",
    "X = torch.cat([embedding_idx, data], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating embedding parameters\n",
    "embedding_size = 5\n",
    "embeddings = torch.nn.Embedding(n_embeddings, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model\n",
    "model = DRSA(\n",
    "    n_features=n_features + 1,  # +1 for the embeddings\n",
    "    hidden_dim=2,\n",
    "    n_layers=1,\n",
    "    embeddings=[embeddings],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training loop\n",
    "def training_loop(X, optimizer, alpha, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "\n",
    "        # weighted average of survival analysis losses\n",
    "        evt_loss = event_time_loss(preds)\n",
    "        evr_loss = event_rate_loss(preds)\n",
    "        loss = (alpha * evt_loss) + ((1 - alpha) * evr_loss)\n",
    "\n",
    "        # updating parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} - loss: {round(loss.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - loss: 12.485\n",
      "epoch: 100 - loss: 10.0184\n",
      "epoch: 200 - loss: 6.5471\n",
      "epoch: 300 - loss: 4.6741\n",
      "epoch: 400 - loss: 3.9786\n",
      "epoch: 500 - loss: 3.5133\n",
      "epoch: 600 - loss: 3.1826\n",
      "epoch: 700 - loss: 2.9421\n",
      "epoch: 800 - loss: 2.7656\n",
      "epoch: 900 - loss: 2.6355\n",
      "epoch: 1000 - loss: 2.5397\n"
     ]
    }
   ],
   "source": [
    "# running training loop\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "training_loop(X, optimizer, alpha=0.5, epochs=1001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
